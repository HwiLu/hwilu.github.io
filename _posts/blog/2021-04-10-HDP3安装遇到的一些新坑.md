---
layout: post
title: HDP3安装遇到的一些新坑
categories: [HDFS,Ambari]
description: ambari
keywords:  HDFS,Ambari
---
# HDP3安装遇到的一些新坑

## 1.Ambari自动生成的repo里源的url地址为空

表现出的现象为Ambari到了安装组件那一步一直过不去，前台报错日志提示ambari和hdp的repo url都为null，无有效的repo，图忘记截了。于是，我们登录到主机查看HDP.repo文件，发现base_url确实是个空值，然后再登录至ambari数据库发现数据库里面base_url字段也是空的。HDP.repo内的空值应该是来着于数据库的base_url字段的空值，于是我们只需要给数据库该字段赋值一个值就可以了。

![空值](/images/posts/20210410/2.png)

### 解决方法

1.登录数据库修改表，指定base_url的值

```bash
sudo mysql -u root -p
use ambari;
update repo_definition set base_url="http://x.x.x.x/hdp/centos7/3.1.0.0-78/" where repo_name="HDP";
update repo_definition set base_url="http://x.x.x.x/hdp-utils/centos7/1.1.0.22/" where repo_name="HDP-UTILS";
update repo_definition set base_url="http://x.x.x.x/hdp-gpl/centos7/3.1.0.0-78/" where repo_name= "HDP-GPL";
```

 2.删除生成的空的repo文件，并且刷新源

```bash
yum clean all && yum makecache
```

3.然后重启服务，不需要重新注册，页面会自动跳转到step9

有些情况HDP-GPL为官网地址，还需要再次更新为实际地址，再此重启ambari-server。

造成这个现象的原因可能是但是建ambari数据库的时候权限没有赋对，导致ambari用户没有权限往数据库里面写内容。

## 2.到了Step9安装Hadoop软件节点，前台提示操作系统存在多个版本的相同软件

报错类似于

```bash
Error: Protected multilib versions: elfutils-libelf-devel-0.152-1.el6.i686 != elfutils-libelf-devel-0.164-2.el6.x86_64
```

原因是为：在操作系统上安装有多个版本不同的同一个软件

![报错](/images/posts/20210410/2.png)

我们可以点开安装的报错按钮，可以看到在哪个过程失败了。比如：看到以下过程的时候失败了。

```bash
yum install -y hadoop_3_1_0_0_78-yarn
```

将该失败过程复制下来在对应的失败的主机上运行一下，看看是具体报什么错（可以直接在后台运行，即使安装成功了也不会影响后续前台的安装）

比如我们看到如下报错：

![报错2](/images/posts/20210410/3.png)

可以看到这三个包安装得有问题。继续排查发现是有些包的版本与操作系统要求的不一致。**直接卸载重新用正确的yum源安装即可（openssl和openssh相关的包不要轻易卸载，会导致主机无法登录），如果没有yum源，则需要下载对应的rpm包进行安装。**

网上说的使用`--setopt=protected_multilib=false `安装发现对我来说并没有什么用。不同的环境各不相同

## 3. 开启namenode HA 发现与原本存在的namenode通信失败

`sudo su hdfs -l -c 'hdfs namenode -bootstrapStandby' `提示

```
21/03/25 17:42:17 INFO namenode.NameNode: createNameNode [-bootstrapStandby]
21/03/25 17:42:17 INFO ha.BootstrapStandby: Found nn: nn1, ipc: hadp-moni-61-29/12.65.61.29:8020
21/03/25 17:42:19 INFO ipc.Client: Retrying connect to server: hadp-moni-61-29/12.65.61.29:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=50, sleepTime=1000 MILLISECONDS)
21/03/25 17:42:20 INFO ipc.Client: Retrying connect to server: hadp-moni-61-29/12.65.61.29:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=50, sleepTime=1000 MILLISECONDS)
21/03/25 17:42:21 INFO ipc.Client: Retrying connect to server: hadp-moni-61-29/12.65.61.29:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=50, sleepTime=1000 MILLISECONDS)
21/03/25 17:42:22 INFO ipc.Client: Retrying connect to server: hadp-moni-61-29/12.65.61.29:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=50, sleepTime=1000 MILLISECONDS)
21/03/25 17:42:23 INFO ipc.Client: Retrying connect to server: hadp-moni-61-29/12.65.61.29:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=50, sleepTime=1000 M
```

8020端口作为namenode的通信端口，居然无法连上，怀疑是namenode服务已经挂掉了。

`ps -ef | grep namenode`发现namenode并没有活着。仔细看namenode HA的开启步骤，有一步是开启原先namenode节点的 zk和nn服务。所以我们可以断定，虽然这一步已经运行结束，但是namenode服务不知道为何又挂掉了，我百思不得其姐。

![HA](/images/posts/20210410/4.png)

现在ambari停留在开启NN HA的界面，无法从前台去启停服务。所以我们到后台去启动namenode

```
sbin/hadoop-daemon.sh start namenode
```

namenode启动成功之后，再运行`sudo su hdfs -l -c 'hdfs namenode -bootstrapStandby' `，发现可以成功了。

经验教训：一定要等目前这一步成功了再进行下一步。

## 4. 启动namenode提示：WARN org.apache.hadoop.hdfs.server.common.Util: Path /data01/hadoop/namenode should be specified as a URI in configuration files. Please update hdfs configuration.

### 问题原因

不合规范的URI格式
### 解决办法
修改hdfs-site.xml 把`dfs.namenode.name.dir`、`dfs.datanode.data.dir`的原路径`/data01/hadoop/namenode`格式如改成`file:///ta01/hadoop/namenode`。



参考

- https://blog.csdn.net/fantasydreams/article/details/46502451
- *https://www.jianshu.com/p/8e4ca48c156a*